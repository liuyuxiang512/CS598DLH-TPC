2022-04-26 19:23:27,874 - INFO - Config:
2022-04-26 19:23:27,874 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/MIMIC/LoS/Transformer",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "d_model": 16,
    "dataset": "MIMIC",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "Transformer",
    "feedforward_size": 256,
    "intermediate_reporting": false,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00017,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "n_epochs": 15,
    "n_heads": 2,
    "n_layers": 6,
    "name": "Transformer",
    "no_diag": true,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "percentage_data": 100.0,
    "positional_encoding": false,
    "save_results_csv": false,
    "seed": 2463121799,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "trans_dropout_rate": 0
}
2022-04-26 19:23:28,472 - INFO - Experiment set up.
2022-04-26 19:23:31,988 - INFO - Transformer(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (trans_dropout): Dropout(p=0, inplace=False)
  (main_dropout): Dropout(p=0.45, inplace=False)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (empty_module): EmptyModule()
  (transformer): TransformerEncoder(
    (input_embedding): Conv1d(204, 16, kernel_size=(1,), stride=(1,))
    (pos_encoder): PositionalEncoding()
    (trans_encoder_layer): TransformerEncoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): Linear(in_features=16, out_features=16, bias=True)
      )
      (linear1): Linear(in_features=16, out_features=256, bias=True)
      (dropout): Dropout(p=0, inplace=False)
      (linear2): Linear(in_features=256, out_features=16, bias=True)
      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0, inplace=False)
      (dropout2): Dropout(p=0, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
  )
  (diagnosis_encoder): Linear(in_features=1, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_los): Linear(in_features=49, out_features=17, bias=True)
  (point_mort): Linear(in_features=49, out_features=17, bias=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
)
2022-04-26 19:34:14,928 - INFO - Custom bins confusion matrix:
2022-04-26 19:34:14,929 - INFO - [[204263 535794 118159  45973  23416  13468   8306   5319  10941   2919]
 [ 95120 317646  98589  45502  25266  15377   9843   6606  14087   3547]
 [ 47090 189141  73318  38047  22557  13978   9136   6297  13267   3582]
 [ 26709 121770  56033  31708  19445  12284   8158   5656  12518   3502]
 [ 17191  85143  44189  25711  16339  10771   7090   5081  11477   3209]
 [ 12057  63040  35410  21350  14044   9272   6304   4447   9988   2763]
 [  8808  48521  29467  18445  12037   8185   5579   3917   8945   2493]
 [  6404  38950  24696  15762  10489   7103   4973   3432   7845   2178]
 [ 19345 123735  87367  59082  40481  28131  19618  13728  32486   9682]
 [ 11619  91469  77849  56982  40741  29422  20997  15260  37368  11950]]
2022-04-26 19:34:22,605 - INFO - Epoch: 0 | Train Loss: 145.4689
2022-04-26 19:36:33,423 - INFO - Custom bins confusion matrix:
2022-04-26 19:36:33,425 - INFO - [[54715 97829 31676 14243  7408  2691   745    30     2     1]
 [21131 57264 27247 16182 10211  4435  1082    82     6     0]
 [ 8911 31936 19595 14141 10375  4961  1240   169    24     0]
 [ 4207 19281 14094 11106  9901  5004  1168   204    22     0]
 [ 2343 12427 10151  8662  9001  4539  1071   145    13     0]
 [ 1381  8155  7632  6731  7609  4111  1003   140    27     0]
 [  894  6074  5864  5182  6492  3470   978   143    35     0]
 [  626  4454  4820  4351  5654  3195   867   150    41     0]
 [ 1249 12061 15698 16985 23312 13000  3443   728   154     0]
 [  758  5891  9144 13247 22135 13857  6086   635   288     0]]
2022-04-26 19:36:34,891 - INFO - Epoch: 0 | Validation Loss: 114.6762
2022-04-26 19:47:17,451 - INFO - Custom bins confusion matrix:
2022-04-26 19:47:17,453 - INFO - [[289450 471509 108423  44650  21752  11768   6938   4316   8148   1604]
 [109579 286624 105145  51796  28404  16796  10364   6619  13437   2819]
 [ 46736 167021  80956  43939  25837  16222  10501   7205  14577   3419]
 [ 23336 104919  60803  36341  22697  14627   9912   6790  14707   3651]
 [ 13597  70697  47245  29951  19430  12931   8732   6209  13886   3523]
 [  8253  50553  37672  24968  16726  11215   7850   5559  12579   3300]
 [  5788  37727  30902  21118  14589  10070   6866   5017  11249   3071]
 [  4043  29277  25642  17893  12373   8669   6083   4472  10428   2952]
 [ 11221  87920  86779  66020  48092  34451  25123  18145  43227  12677]
 [  5333  57595  72162  60975  47178  35533  26666  19574  51390  17251]]
2022-04-26 19:47:22,687 - INFO - Epoch: 1 | Train Loss: 126.3726
2022-04-26 19:49:31,671 - INFO - Custom bins confusion matrix:
2022-04-26 19:49:31,674 - INFO - [[74619 83583 29164 13135  5052  2267  1061   340   117     2]
 [27863 52331 26679 15358  7828  4334  2296   703   248     0]
 [11690 29610 20006 12610  8136  5183  2668   998   451     0]
 [ 5545 18045 14345 10400  7168  4991  2940  1084   469     0]
 [ 2936 11862 10118  8233  6195  4801  2801   995   411     0]
 [ 1810  7671  7278  6534  5257  4168  2548  1115   408     0]
 [ 1125  5568  5778  4847  4383  3698  2275  1058   400     0]
 [  777  4223  4539  4019  3643  3424  2183  1003   347     0]
 [ 1600 11540 15284 14723 15148 13470  8904  4140  1821     0]
 [ 1094  5382  8830 10562 12626 12923 10636  5775  4213     0]]
2022-04-26 19:49:33,157 - INFO - Epoch: 1 | Validation Loss: 108.7353
2022-04-26 20:00:18,885 - INFO - Custom bins confusion matrix:
2022-04-26 20:00:18,886 - INFO - [[337022 429518 108796  43673  20477  10783   6312   3673   6899   1405]
 [120936 269702 110949  53717  28667  16278   9823   6495  12417   2599]
 [ 49382 157047  84508  46683  26626  16453  10533   6991  14774   3416]
 [ 23720  97427  63844  38017  23589  15084  10197   6885  15157   3863]
 [ 13506  64573  48763  31376  20358  13446   9135   6516  14521   4007]
 [  8166  45692  38623  26061  17458  11688   8140   5874  13259   3714]
 [  5453  33981  31123  21932  14956  10361   7437   5132  12340   3682]
 [  3796  25911  25925  18410  12946   9073   6293   4647  11300   3531]
 [ 10926  75851  85280  66843  49475  35670  26403  19218  47951  16038]
 [  5470  47311  68118  59830  47522  35856  27822  21212  57430  23086]]
2022-04-26 20:00:23,767 - INFO - Epoch: 2 | Train Loss: 120.2984
2022-04-26 20:02:32,919 - INFO - Custom bins confusion matrix:
2022-04-26 20:02:32,921 - INFO - [[85138 76254 26485 12245  5136  2235  1300   366   179     2]
 [30727 50020 25360 14980  8280  4327  2654   892   400     0]
 [12585 28469 19053 12321  8009  5678  3284  1271   682     0]
 [ 5818 17805 13132 10082  7126  5171  3681  1404   768     0]
 [ 3073 11600  9278  7683  6210  4872  3400  1485   751     0]
 [ 1877  7464  6731  5925  5149  4310  3027  1495   811     0]
 [ 1195  5435  5139  4527  4320  3525  2734  1468   789     0]
 [  831  4053  4109  3730  3380  3238  2681  1444   692     0]
 [ 1825 10943 13526 13206 13508 13357 10851  5666  3748     0]
 [ 1260  4810  8144  8902 10295 11716 11805  7907  7202     0]]
2022-04-26 20:02:34,608 - INFO - Epoch: 2 | Validation Loss: 104.5940
2022-04-26 20:13:20,447 - INFO - Custom bins confusion matrix:
2022-04-26 20:13:20,449 - INFO - [[361129 410556 106440  42692  20178  10342   6069   3564   6364   1224]
 [124342 264121 112694  54547  28712  16480  10068   6215  11956   2448]
 [ 49222 152333  86238  47919  27862  17076  10792   7211  14502   3258]
 [ 22639  93379  64676  39547  24362  16031  10557   7250  15493   3849]
 [ 12763  60545  49235  32513  21329  14299   9679   6622  15190   4026]
 [  7834  42117  38552  26692  17995  12631   8654   6077  14114   4009]
 [  5244  30885  30853  22558  15709  10890   7726   5565  13090   3877]
 [  3635  23484  25123  19196  13440   9406   6729   4912  12000   3907]
 [ 10644  67220  81737  67506  50608  37784  27676  20839  52285  17356]
 [  5517  39643  63159  58892  48273  37501  29202  22542  62697  26231]]
2022-04-26 20:13:25,596 - INFO - Epoch: 3 | Train Loss: 115.6453
2022-04-26 20:15:36,078 - INFO - Custom bins confusion matrix:
2022-04-26 20:15:36,080 - INFO - [[89616 74488 24709 11347  4940  2139  1205   578   316     2]
 [31844 50168 24244 14463  7965  4186  2652  1418   700     0]
 [12807 28577 18282 11983  7767  5362  3399  2056  1119     0]
 [ 5878 17875 12448  9784  6705  4998  3557  2379  1363     0]
 [ 3087 11596  8789  7291  5855  4622  3424  2231  1457     0]
 [ 1832  7405  6613  5337  4784  4151  2999  2087  1581     0]
 [ 1173  5322  5049  4075  3932  3503  2502  1962  1614     0]
 [  834  3924  3948  3538  3075  2914  2542  1924  1459     0]
 [ 1871 10579 12873 12268 11905 12001 10641  7587  6905     0]
 [ 1268  4697  7600  7997  8552 10237 10637  9054 11999     0]]
2022-04-26 20:15:37,666 - INFO - Epoch: 3 | Validation Loss: 101.5650
2022-04-26 20:26:19,361 - INFO - Custom bins confusion matrix:
2022-04-26 20:26:19,362 - INFO - [[369988 404409 105023  42071  19852  10412   6007   3497   6084   1215]
 [124701 261615 113814  55149  29520  16489   9896   6383  11749   2267]
 [ 48458 149054  87159  49040  28631  17469  11036   7364  14907   3295]
 [ 21770  90366  65075  40417  25826  16369  10847   7402  15867   3844]
 [ 12033  58022  49302  33382  22164  14517  10088   7014  15625   4054]
 [  7246  39995  38047  27310  18893  12962   9165   6394  14743   3920]
 [  4911  28973  30060  23095  16341  11478   8032   5742  13739   4026]
 [  3480  21803  24600  19185  13988   9856   7114   5260  12664   3882]
 [ 10346  60640  78866  67773  52350  39377  29053  21593  55293  18364]
 [  5475  34372  58782  57352  48984  38959  30398  23698  67475  28162]]
2022-04-26 20:26:24,255 - INFO - Epoch: 4 | Train Loss: 112.4857
2022-04-26 20:28:35,662 - INFO - Custom bins confusion matrix:
2022-04-26 20:28:35,664 - INFO - [[87908 75959 24316 11669  5047  2275  1150   583   431     2]
 [30440 50616 24324 14613  8134  4340  2700  1516   957     0]
 [11818 28557 18111 12261  7928  5440  3448  2151  1638     0]
 [ 5234 17707 12442  9745  6853  5041  3558  2401  2006     0]
 [ 2768 11230  8613  7622  5802  4534  3446  2266  2071     0]
 [ 1623  7091  6382  5538  4798  4021  3113  2065  2158     0]
 [ 1071  5077  4913  4124  3925  3445  2422  1863  2292     0]
 [  771  3691  3868  3527  3131  2738  2447  1806  2179     0]
 [ 1782  9640 12532 12223 11677 11296 10317  7726  9437     0]
 [ 1161  4467  6917  8204  7723 10007 10290  8354 14918     0]]
2022-04-26 20:28:37,245 - INFO - Epoch: 4 | Validation Loss: 99.8584
2022-04-26 20:39:20,261 - INFO - Custom bins confusion matrix:
2022-04-26 20:39:20,262 - INFO - [[375672 400444 104547  42124  19499  10142   5766   3409   5914   1041]
 [125105 258718 115128  56256  29575  16784   9935   6245  11635   2202]
 [ 47901 146236  88709  49961  29147  18042  11247   7397  14770   3003]
 [ 21287  87410  66172  41556  26133  16736  11311   7586  15976   3616]
 [ 11700  55868  49417  34084  22640  15023  10279   7150  16003   4037]
 [  6969  38196  38006  27695  19462  13320   9257   6657  15086   4027]
 [  4647  27490  29941  23169  16707  11782   8150   6109  14355   4047]
 [  3345  20374  24751  19220  14034  10111   7547   5353  13273   3824]
 [ 10021  56064  77309  67471  52876  40197  29875  22571  58116  19155]
 [  5406  30813  56022  56678  48537  39693  31264  24724  70534  29986]]
2022-04-26 20:39:25,053 - INFO - Epoch: 5 | Train Loss: 110.1691
2022-04-26 20:41:36,723 - INFO - Custom bins confusion matrix:
2022-04-26 20:41:36,726 - INFO - [[88040 77482 23745 11033  4761  2129  1125   512   511     2]
 [30160 51583 24414 14051  8017  4089  2555  1534  1237     0]
 [11453 29220 18244 11848  7695  5169  3395  2261  2067     0]
 [ 5074 17992 12474  9534  6531  4926  3446  2458  2552     0]
 [ 2629 11356  8690  7483  5605  4341  3344  2285  2619     0]
 [ 1569  7125  6380  5431  4623  3915  2988  2138  2619     1]
 [ 1012  5083  4954  4077  3762  3220  2412  1813  2799     0]
 [  753  3649  3927  3486  3013  2557  2325  1789  2659     0]
 [ 1768  9466 12593 11969 11122 10334 10051  7936 11391     0]
 [ 1175  4547  6734  8228  7209  9155  9499  8064 17416    14]]
2022-04-26 20:41:38,238 - INFO - Epoch: 5 | Validation Loss: 98.6147
2022-04-26 20:52:13,282 - INFO - Custom bins confusion matrix:
2022-04-26 20:52:13,284 - INFO - [[379189 397538 105611  41826  19257   9882   5322   3336   5555   1042]
 [125855 255977 117574  56412  29785  16635  10076   6088  11168   2013]
 [ 47623 144058  89987  51023  29727  17846  11428   7523  14339   2859]
 [ 21168  85175  67285  42046  26476  17100  11233   7711  16002   3587]
 [ 11265  54349  49914  34475  22976  15412  10350   7380  16197   3883]
 [  6708  36904  38033  28042  19365  13714   9526   6798  15543   4042]
 [  4499  26191  30138  23486  16889  11862   8677   6118  14496   4041]
 [  3179  19462  24465  19464  14504  10182   7661   5555  13419   3941]
 [  9595  52738  76110  67294  53923  40419  31067  23048  59767  19694]
 [  5198  28472  53801  55961  48729  40156  31846  25325  73153  31016]]
2022-04-26 20:52:18,098 - INFO - Epoch: 6 | Train Loss: 108.4433
2022-04-26 20:54:21,629 - INFO - Custom bins confusion matrix:
2022-04-26 20:54:21,632 - INFO - [[88429 77548 23621 10748  4792  2079  1105   494   522     2]
 [30099 51632 24446 14040  7966  4085  2530  1495  1347     0]
 [11403 29129 18296 11832  7642  5237  3300  2194  2319     0]
 [ 4960 17937 12522  9408  6497  5010  3390  2396  2861     6]
 [ 2585 11176  8744  7454  5617  4397  3192  2251  2936     0]
 [ 1501  7001  6302  5559  4601  3865  3028  2067  2857     8]
 [  999  4917  5023  4098  3698  3189  2465  1655  3088     0]
 [  749  3546  3959  3467  2996  2480  2260  1785  2916     0]
 [ 1765  9134 12418 11928 10961 10205  9811  7738 12659    11]
 [ 1175  4490  6533  8026  7340  8686  9049  7809 18577   356]]
2022-04-26 20:54:23,173 - INFO - Epoch: 6 | Validation Loss: 97.6636
2022-04-26 21:04:42,519 - INFO - Custom bins confusion matrix:
2022-04-26 21:04:42,521 - INFO - [[380478 397056 106487  41328  18841   9691   5288   3207   5254    928]
 [125786 254308 119546  57017  29796  16429   9738   6047  10945   1971]
 [ 47559 142208  91379  51298  29897  18039  11577   7458  14217   2781]
 [ 20799  83649  67921  42895  26602  17265  11429   7842  15875   3506]
 [ 11027  53106  50420  34684  23362  15722  10575   7318  16080   3907]
 [  6601  35739  38030  28550  19729  13940   9635   6866  15541   4044]
 [  4375  25292  30126  23533  17139  12147   8760   6344  14517   4164]
 [  3080  18602  24205  19719  14524  10529   7770   5724  13533   4146]
 [  9461  49978  74884  67844  54025  41561  31486  23767  60396  20253]
 [  5158  26670  52039  55906  48646  40008  32457  25468  74732  32573]]
2022-04-26 21:04:47,350 - INFO - Epoch: 7 | Train Loss: 107.1378
2022-04-26 21:06:46,465 - INFO - Custom bins confusion matrix:
2022-04-26 21:06:46,467 - INFO - [[89707 77546 23139 10243  4620  2015  1064   476   528     2]
 [30565 51984 24245 13705  7778  4062  2462  1438  1400     1]
 [11509 29449 18313 11520  7527  5200  3294  2073  2460     7]
 [ 5039 18138 12474  9220  6365  4981  3427  2306  3026    11]
 [ 2629 11305  8779  7266  5589  4353  3141  2212  3075     3]
 [ 1545  7018  6336  5484  4577  3817  2991  1972  3039    10]
 [ 1014  4937  5007  4115  3686  3044  2486  1631  3206     6]
 [  771  3555  4003  3349  3024  2435  2135  1853  3023    10]
 [ 1841  9219 12413 11656 10826 10132  9378  7659 13482    24]
 [ 1208  4644  6668  7522  7602  8297  8607  7622 19076   795]]
2022-04-26 21:06:48,020 - INFO - Epoch: 7 | Validation Loss: 96.9836
2022-04-26 21:17:09,522 - INFO - Custom bins confusion matrix:
2022-04-26 21:17:09,524 - INFO - [[380173 397200 108200  40518  18534   9447   5231   3082   5266    907]
 [125729 252679 121722  57159  29619  16498   9779   5943  10594   1861]
 [ 47201 140141  93532  51815  30113  18091  11502   7260  14047   2711]
 [ 20601  81750  69392  43316  27276  16944  11546   7771  15785   3402]
 [ 10843  51859  50684  35558  23871  15390  10707   7334  16174   3781]
 [  6487  34685  38242  28707  20414  13898   9807   6991  15544   3900]
 [  4280  24469  30178  23766  17173  12397   8820   6320  14864   4130]
 [  3038  17766  24326  19967  14640  10762   7811   5680  13727   4115]
 [  9130  48021  74036  67523  55272  42106  31800  23810  61364  20593]
 [  5039  25288  49731  55239  48978  40712  32537  25918  76200  34015]]
2022-04-26 21:17:14,391 - INFO - Epoch: 8 | Train Loss: 106.0086
2022-04-26 21:19:10,740 - INFO - Custom bins confusion matrix:
2022-04-26 21:19:10,742 - INFO - [[90168 78122 22829  9798  4409  1955  1033   487   531     8]
 [30508 52706 24295 13220  7622  4018  2399  1429  1419    24]
 [11445 29681 18504 11255  7534  5042  3273  1999  2597    22]
 [ 5028 18264 12543  8973  6436  4849  3415  2272  3187    20]
 [ 2584 11387  8916  7018  5588  4274  3108  2205  3262    10]
 [ 1541  7078  6337  5393  4546  3699  2997  1980  3193    25]
 [ 1031  4904  5061  4090  3573  3000  2468  1658  3320    27]
 [  758  3600  3949  3344  3014  2400  2067  1815  3184    27]
 [ 1872  9267 12401 11223 10793  9897  8982  7692 14328   175]
 [ 1178  4807  6596  7067  7661  7876  8245  7497 19803  1311]]
2022-04-26 21:19:12,272 - INFO - Epoch: 8 | Validation Loss: 96.1995
2022-04-26 21:29:35,721 - INFO - Custom bins confusion matrix:
2022-04-26 21:29:35,723 - INFO - [[380393 397041 109217  40309  18306   9162   5152   3002   5145    831]
 [125008 251823 123483  57352  29455  16504   9592   6103  10517   1746]
 [ 47133 138254  94970  52258  30260  18184  11561   7396  13810   2587]
 [ 20453  80311  70140  43901  27455  17425  11667   7674  15405   3352]
 [ 10624  50780  51550  35414  23716  15889  10996   7476  16089   3667]
 [  6389  33843  38638  28959  20328  13925   9935   7136  15601   3921]
 [  4208  23721  30402  24157  17454  12369   8936   6351  14762   4037]
 [  2924  17312  24118  20106  15107  10880   7799   5657  13827   4102]
 [  9073  46090  72856  68303  55075  42597  32101  24223  61999  21338]
 [  4895  24222  47975  54316  48896  40837  32874  26554  77453  35635]]
2022-04-26 21:29:40,597 - INFO - Epoch: 9 | Train Loss: 105.0966
2022-04-26 21:31:41,248 - INFO - Custom bins confusion matrix:
2022-04-26 21:31:41,249 - INFO - [[88762 79209 23519  9623  4367  1897   971   478   505     9]
 [29690 52928 25105 13417  7576  3952  2277  1388  1272    35]
 [11108 29492 18995 11543  7694  4987  3238  1863  2409    23]
 [ 4814 18196 12762  9178  6630  4860  3353  2194  2979    21]
 [ 2446 11279  9177  7128  5646  4352  3101  2143  3069    11]
 [ 1473  6910  6490  5571  4593  3799  2971  1942  3013    27]
 [  979  4757  5234  4179  3707  2974  2426  1680  3162    34]
 [  707  3500  4046  3444  3117  2411  2035  1779  3090    29]
 [ 1797  9106 12399 11397 11152 10068  8870  7601 14013   227]
 [ 1126  4695  6734  7013  7899  7934  8223  7450 19460  1507]]
2022-04-26 21:31:42,744 - INFO - Epoch: 9 | Validation Loss: 95.7005
2022-04-26 21:42:00,937 - INFO - Custom bins confusion matrix:
2022-04-26 21:42:00,939 - INFO - [[380177 397786 109809  39659  18015   9171   5050   3070   5014    807]
 [124413 251368 124685  57708  29593  16456   9650   5815  10134   1761]
 [ 46794 137293  95751  52763  30860  18244  11333   7239  13665   2471]
 [ 20399  79180  70547  44131  28053  17671  11590   7645  15439   3128]
 [ 10585  49803  51466  36339  23998  16040  10781   7509  16056   3624]
 [  6258  33269  38347  29432  20660  14395   9982   7037  15474   3821]
 [  4168  23082  30074  24292  17725  12564   8989   6446  14891   4166]
 [  2938  16827  24017  20104  15250  11031   7877   5717  13929   4142]
 [  8845  44661  72029  67367  55906  43368  32551  24771  62597  21560]
 [  4738  23402  46576  53335  48719  41477  33176  26506  78755  36973]]
2022-04-26 21:42:05,794 - INFO - Epoch: 10 | Train Loss: 104.2232
2022-04-26 21:44:08,156 - INFO - Custom bins confusion matrix:
2022-04-26 21:44:08,158 - INFO - [[89801 78582 23454  9362  4256  1855   974   512   528    16]
 [30011 52699 25387 13154  7465  3854  2269  1417  1339    45]
 [11236 29335 19140 11386  7597  5057  3160  1885  2508    48]
 [ 4902 18070 12881  9051  6536  4833  3386  2189  3107    32]
 [ 2504 11169  9309  6968  5593  4337  3076  2195  3175    26]
 [ 1502  6818  6568  5456  4526  3827  2940  1986  3110    56]
 [ 1000  4688  5230  4116  3690  2965  2418  1683  3279    63]
 [  719  3464  4027  3417  3078  2402  1987  1771  3242    51]
 [ 1837  9005 12288 11039 11073  9993  8711  7495 14819   370]
 [ 1136  4568  6775  6772  7706  7644  8054  7364 20000  2022]]
2022-04-26 21:44:09,627 - INFO - Epoch: 10 | Validation Loss: 95.1302
2022-04-26 21:54:30,249 - INFO - Custom bins confusion matrix:
2022-04-26 21:54:30,251 - INFO - [[380823 396721 110841  39313  18085   9164   4902   2914   4955    840]
 [124885 249271 126641  57716  29714  16202   9560   5931   9999   1664]
 [ 46925 135859  96678  53402  30515  18713  11306   7182  13438   2395]
 [ 20182  78349  70995  44330  28397  18066  11655   7684  14978   3147]
 [ 10649  48878  51591  36619  24444  16192  11079   7539  15726   3484]
 [  6150  32709  38197  29801  21047  14496  10089   6931  15440   3815]
 [  4167  22445  30031  24382  17985  12634   9217   6542  14921   4073]
 [  2900  16427  24021  20103  15125  11163   8111   5779  13891   4312]
 [  8627  43652  70506  67835  56292  43650  32817  24895  63398  21983]
 [  4640  22465  45065  52755  48415  41032  33671  26819  80426  38369]]
2022-04-26 21:54:35,430 - INFO - Epoch: 11 | Train Loss: 103.4504
2022-04-26 21:56:41,071 - INFO - Custom bins confusion matrix:
2022-04-26 21:56:41,073 - INFO - [[88672 79258 23932  9329  4323  1822   967   517   502    18]
 [29288 52782 25904 13382  7517  3853  2264  1330  1276    44]
 [10898 29156 19609 11469  7705  5107  3124  1903  2331    50]
 [ 4752 17863 13223  9080  6571  4947  3412  2178  2934    27]
 [ 2412 10999  9598  6961  5640  4413  3092  2215  2999    23]
 [ 1473  6651  6781  5444  4629  3905  2899  1969  2987    51]
 [  972  4603  5292  4134  3803  2984  2434  1658  3191    61]
 [  695  3394  4087  3465  3111  2457  1974  1780  3142    53]
 [ 1772  8733 12436 11087 11223 10239  8682  7498 14574   386]
 [ 1086  4324  6951  6732  7772  7867  8190  7416 19646  2057]]
2022-04-26 21:56:42,567 - INFO - Epoch: 11 | Validation Loss: 94.8544
2022-04-26 22:07:10,332 - INFO - Custom bins confusion matrix:
2022-04-26 22:07:10,335 - INFO - [[380771 395549 112878  39072  17809   9131   4846   2924   4795    783]
 [124401 247968 128396  58105  29439  16666   9620   5605   9767   1616]
 [ 46430 134518  98149  53574  30967  18573  11607   7117  13250   2228]
 [ 20183  77072  71387  45020  28473  18056  11779   7678  15205   2930]
 [ 10429  48060  52105  36807  24542  16403  11203   7583  15652   3417]
 [  6176  31808  38432  29785  20986  15044  10151   7112  15418   3763]
 [  4051  21933  30144  24448  17900  13105   9177   6810  14798   4031]
 [  2826  15947  23846  20368  15357  11291   8092   5807  14075   4223]
 [  8632  42396  69559  68011  56379  43854  33459  24943  64100  22322]
 [  4649  21607  43926  52136  48394  41733  33852  26834  81029  39497]]
2022-04-26 22:07:15,258 - INFO - Epoch: 12 | Train Loss: 102.8568
2022-04-26 22:09:14,865 - INFO - Custom bins confusion matrix:
2022-04-26 22:09:14,867 - INFO - [[87650 79217 24763  9373  4375  1877  1009   535   521    20]
 [28684 52182 26666 13490  7604  3929  2376  1349  1315    45]
 [10605 28627 19975 11567  7788  5171  3226  1978  2363    52]
 [ 4594 17452 13468  9042  6613  4987  3550  2237  3013    31]
 [ 2348 10717  9773  6844  5603  4480  3195  2247  3113    32]
 [ 1431  6438  6865  5395  4543  3969  2918  2074  3095    61]
 [  947  4444  5361  4046  3718  3082  2461  1725  3275    73]
 [  669  3275  4105  3457  3047  2465  2034  1791  3244    71]
 [ 1701  8361 12386 10813 11128 10247  8734  7567 15148   545]
 [ 1029  4151  6821  6692  7538  7783  8023  7399 20246  2359]]
2022-04-26 22:09:16,381 - INFO - Epoch: 12 | Validation Loss: 94.4703
2022-04-26 22:19:41,673 - INFO - Custom bins confusion matrix:
2022-04-26 22:19:41,675 - INFO - [[380478 384065 125640  38684  17372   9086   4896   2868   4707    762]
 [124611 237309 139797  57790  29679  16277   9376   5599   9661   1484]
 [ 46849 126359 105762  54067  30588  18621  11391   7354  13175   2247]
 [ 20069  71679  76529  45307  28796  18045  11768   7484  15177   2929]
 [ 10469  43790  55576  36851  24904  16702  11156   7577  15623   3553]
 [  6109  28849  41118  29897  21341  14707  10306   7227  15313   3808]
 [  3941  19794  31800  24881  18086  13165   9200   6553  14974   4003]
 [  2855  14381  24868  20546  15423  11447   8147   5922  14101   4142]
 [  8443  38424  71753  67517  56841  44482  33882  25344  64327  22642]
 [  4523  19639  44312  50961  48233  41648  33879  27370  81974  41118]]
2022-04-26 22:19:46,507 - INFO - Epoch: 13 | Train Loss: 102.2004
2022-04-26 22:21:49,856 - INFO - Custom bins confusion matrix:
2022-04-26 22:21:49,858 - INFO - [[88818 77434 25912  9029  4227  1872   989   526   513    20]
 [29209 51060 27901 13163  7440  3895  2378  1271  1278    45]
 [10771 28026 20804 11385  7715  5175  3212  1912  2298    54]
 [ 4725 16974 14084  8966  6566  4949  3531  2191  2968    33]
 [ 2408 10370 10189  6852  5498  4472  3239  2194  3091    39]
 [ 1460  6230  7223  5295  4406  4097  2919  1966  3123    70]
 [  987  4284  5537  4038  3693  3069  2464  1747  3229    84]
 [  697  3155  4237  3448  3029  2454  2087  1759  3217    75]
 [ 1739  8159 12675 10631 11072 10248  8795  7451 15219   641]
 [ 1032  3965  7146  6521  7345  7830  8059  7273 20335  2535]]
2022-04-26 22:21:51,573 - INFO - Epoch: 13 | Validation Loss: 94.0142
2022-04-26 22:32:14,128 - INFO - Custom bins confusion matrix:
2022-04-26 22:32:14,130 - INFO - [[380874 382448 127594  38345  17404   8712   4888   2830   4694    769]
 [124321 235439 142397  58085  29406  15977   9223   5567   9666   1502]
 [ 46637 124627 107907  54024  31266  18504  11284   7046  12941   2177]
 [ 20079  70050  77976  45566  28736  18334  11855   7719  14661   2807]
 [ 10547  42702  56324  37134  24851  16788  11180   7500  15730   3445]
 [  6074  27926  41732  30136  21424  14916  10245   7123  15433   3666]
 [  3995  19250  32019  24743  18179  13155   9352   6655  15033   4016]
 [  2752  13993  25166  20498  15729  11340   8133   5996  14063   4162]
 [  8517  37156  71775  66961  57086  44903  33598  25220  65245  23194]
 [  4474  18790  43417  50126  48020  41088  33853  27731  83621  42537]]
2022-04-26 22:32:19,099 - INFO - Epoch: 14 | Train Loss: 101.6582
2022-04-26 22:34:22,746 - INFO - Custom bins confusion matrix:
2022-04-26 22:34:22,749 - INFO - [[87466 77831 26622  9253  4252  1855  1014   529   501    17]
 [28425 50819 28574 13494  7522  3956  2341  1228  1243    38]
 [10449 27639 21152 11721  7822  5202  3223  1866  2235    43]
 [ 4560 16693 14346  9091  6673  4987  3551  2159  2903    24]
 [ 2317 10165 10353  6919  5522  4562  3332  2136  3006    40]
 [ 1420  6077  7301  5344  4457  4153  2939  1868  3156    74]
 [  925  4201  5609  4065  3792  3050  2425  1760  3226    79]
 [  657  3071  4245  3496  3085  2477  2113  1757  3177    80]
 [ 1649  7775 12752 10800 11040 10376  8992  7420 15147   679]
 [  995  3726  7079  6664  7355  7950  8127  7300 20357  2488]]
2022-04-26 22:34:24,386 - INFO - Epoch: 14 | Validation Loss: 93.7414
2022-04-26 22:34:24,398 - INFO - Experiment ended. Checkpoints stored =)
