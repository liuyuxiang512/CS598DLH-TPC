2022-04-17 02:29:39,497 - INFO - Config:
2022-04-17 02:29:39,498 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/Transformer",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "d_model": 16,
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "Transformer",
    "feedforward_size": 256,
    "intermediate_reporting": false,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00017,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "n_epochs": 15,
    "n_heads": 2,
    "n_layers": 6,
    "name": "Transformer",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "percentage_data": 100.0,
    "positional_encoding": false,
    "save_results_csv": false,
    "seed": 3257280589,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "trans_dropout_rate": 0
}
2022-04-17 02:29:45,936 - INFO - Experiment set up.
2022-04-17 02:29:49,275 - INFO - Transformer(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (trans_dropout): Dropout(p=0, inplace=False)
  (main_dropout): Dropout(p=0.45, inplace=False)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (empty_module): EmptyModule()
  (transformer): TransformerEncoder(
    (input_embedding): Conv1d(176, 16, kernel_size=(1,), stride=(1,))
    (pos_encoder): PositionalEncoding()
    (trans_encoder_layer): TransformerEncoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): Linear(in_features=16, out_features=16, bias=True)
      )
      (linear1): Linear(in_features=16, out_features=256, bias=True)
      (dropout): Dropout(p=0, inplace=False)
      (linear2): Linear(in_features=256, out_features=16, bias=True)
      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0, inplace=False)
      (dropout2): Dropout(p=0, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
  )
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_los): Linear(in_features=145, out_features=17, bias=True)
  (point_mort): Linear(in_features=145, out_features=17, bias=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
)
2022-04-17 02:48:42,921 - INFO - Custom bins confusion matrix:
2022-04-17 02:48:42,922 - INFO - [[901420 920487 158101  59554  28315  14466   8216   4528   7161    755]
 [383296 565034 145122  65685  34003  18503  10354   6108   9246   1100]
 [176026 336646 114485  57457  31566  17457   9895   6034   9345   1082]
 [ 91639 210755  88179  48570  27218  15586   9024   5388   8646   1025]
 [ 52570 142109  68061  39450  22796  13205   7735   4735   7684    931]
 [ 33018  99668  53510  32627  19438  11275   6768   4103   6790    858]
 [ 21711  72827  43526  27277  16281   9761   5827   3617   5872    741]
 [ 14142  54914  35426  22798  13983   8435   5046   3033   5279    685]
 [ 35607 160157 115133  77727  49586  30159  18765  11885  20183   2624]
 [ 16497  86649  75934  55631  36490  23161  14496   9367  16423   2180]]
2022-04-17 02:48:50,628 - INFO - Epoch: 0 | Train Loss: 113.0718
2022-04-17 02:52:25,544 - INFO - Custom bins confusion matrix:
2022-04-17 02:52:25,546 - INFO - [[175685 206764  36382  14840   9093   4390   1771    693    324      0]
 [ 63670 122728  33875  19293  12853   6632   2643   1065    483      0]
 [ 26757  68613  24477  16936  13156   6908   2809   1195    541      0]
 [ 13228  39407  17658  13859  11648   6398   2792   1168    629      0]
 [  7088  24036  12763  11186  10291   5623   2765   1151    639      0]
 [  4224  16214   9663   8909   8535   5077   2780   1078    668      0]
 [  2627  10807   7250   6904   7150   4453   2633    947    689      0]
 [  1790   7822   5512   5630   5981   4032   2298    894    666      0]
 [  3146  20052  16690  18399  20991  15227   9329   4155   3207      0]
 [  1131   9838   9341  10447  15058  10960   8836   3648   2429      0]]
2022-04-17 02:52:27,537 - INFO - Epoch: 0 | Validation Loss: 98.7292
2022-04-17 03:10:47,792 - INFO - Custom bins confusion matrix:
2022-04-17 03:10:47,794 - INFO - [[983975 865698 137873  54190  26127  14129   8050   4714   7333    914]
 [381166 556603 144853  68959  36752  20163  11519   6678  10487   1271]
 [163786 328800 116036  62874  35676  20522  12031   7185  11603   1480]
 [ 79807 200927  89601  53953  31892  18825  11295   6799  11351   1580]
 [ 43885 130131  68282  43827  27465  16672  10344   6280  10912   1478]
 [ 26649  88163  52668  36083  23105  14693   9191   5888  10109   1506]
 [ 17030  61597  42123  30257  19813  12558   8134   5147   9343   1438]
 [ 10570  44366  33959  25329  17100  11129   6969   4643   8396   1280]
 [ 24372 119870 105895  85385  60338  40686  26886  18138  34318   5938]
 [  9815  56351  63137  57701  44663  31786  22123  15115  30587   5550]]
2022-04-17 03:10:55,515 - INFO - Epoch: 1 | Train Loss: 101.4047
2022-04-17 03:14:29,898 - INFO - Custom bins confusion matrix:
2022-04-17 03:14:29,899 - INFO - [[177337 211401  35857  13845   7147   2747   1042    433    133      0]
 [ 61259 128961  37453  19377  10125   3837   1594    471    165      0]
 [ 24683  72603  27995  18399  10750   4309   1787    657    209      0]
 [ 12010  41316  20915  15187   9975   4456   1956    729    243      0]
 [  6126  25298  15233  12502   8949   4375   1953    746    360      0]
 [  3609  16828  11437  10398   7655   4051   1932    865    373      0]
 [  2249  11127   8354   8365   6622   3795   1760    887    301      0]
 [  1494   7830   6497   6786   5795   3403   1668    883    269      0]
 [  2805  19567  19265  21789  21212  13820   7772   3321   1645      0]
 [  1069   9027  10533  12775  15186  10964   6760   3482   1892      0]]
2022-04-17 03:14:32,006 - INFO - Epoch: 1 | Validation Loss: 95.0876
2022-04-17 03:33:06,865 - INFO - Custom bins confusion matrix:
2022-04-17 03:33:06,867 - INFO - [[1000629  851275  137960   54035   25749   13550    7589    4386    6906
      924]
 [ 375368  557610  149385   70873   36312   19777   11068    6509   10201
     1348]
 [ 157877  327447  120060   65686   36220   20439   11816    7231   11684
     1533]
 [  75293  198359   92347   55328   32701   19275   11764    7107   12119
     1737]
 [  40731  126961   70147   45294   28189   17128   10746    6686   11751
     1643]
 [  24697   84257   53515   37513   24376   15279    9555    6094   11106
     1663]
 [  15502   58271   42027   30994   20968   13553    8559    5685   10247
     1634]
 [   9760   41133   33609   26159   17839   11725    7662    4971    9365
     1518]
 [  22163  107693  102779   87273   63656   43790   29350   19731   38475
     6916]
 [   8790   49110   58113   57121   46244   34380   23796   16677   35283
     7314]]
2022-04-17 03:33:14,866 - INFO - Epoch: 2 | Train Loss: 98.1689
2022-04-17 03:36:50,582 - INFO - Custom bins confusion matrix:
2022-04-17 03:36:50,583 - INFO - [[198741 193706  34695  13476   5852   2209    930    244     89      0]
 [ 69659 123973  37737  18954   8354   2959   1114    384    108      0]
 [ 28104  70866  29597  18219   8997   3552   1400    531    126      0]
 [ 13537  40715  22302  15383   8686   3877   1485    638    164      0]
 [  6824  25153  16321  12817   8086   3916   1528    640    257      0]
 [  3965  16825  12188  10995   6862   3658   1689    697    269      0]
 [  2474  10998   8885   8966   6278   3376   1502    727    254      0]
 [  1691   7710   7067   7257   5441   3090   1446    672    251      0]
 [  3315  19057  21058  23333  20514  13173   6458   2597   1691      0]
 [  1306   8584  11012  14462  14675  10413   6547   2867   1822      0]]
2022-04-17 03:36:52,845 - INFO - Epoch: 2 | Validation Loss: 93.3433
2022-04-17 03:54:59,112 - INFO - Custom bins confusion matrix:
2022-04-17 03:54:59,114 - INFO - [[1004229  848671  139652   53420   24785   13210    7275    4238    6637
      886]
 [ 370239  560110  152708   70701   36962   19696   10782    6405    9641
     1207]
 [ 153088  328892  122446   66546   36415   20385   11838    7259   11628
     1496]
 [  71697  198728   93854   56393   33354   19576   11530    7172   12060
     1666]
 [  38314  125977   71030   46422   28741   17477   10983    6665   11887
     1780]
 [  22972   83129   53855   38239   25050   15581    9812    6397   11171
     1849]
 [  14380   56916   42408   31953   21145   13850    8793    5707   10569
     1719]
 [   9080   39326   33524   26366   18514   12161    7902    5241    9909
     1718]
 [  20887  100815  101022   88338   65210   45312   30561   20660   41197
     7824]
 [   8294   44336   55526   56074   46772   34940   25327   17790   39153
     8616]]
2022-04-17 03:55:06,944 - INFO - Epoch: 3 | Train Loss: 96.3097
2022-04-17 03:58:34,979 - INFO - Custom bins confusion matrix:
2022-04-17 03:58:34,981 - INFO - [[209831 183046  34945  13159   5524   2264    852    251     70      0]
 [ 73878 120066  38033  18843   8005   2857   1121    353     86      0]
 [ 29809  68798  30367  18053   8877   3475   1376    500    137      0]
 [ 14214  39898  22304  15699   8544   3836   1494    626    172      0]
 [  7171  24633  16381  13040   7941   3912   1537    685    242      0]
 [  4160  16575  12231  11018   6826   3588   1783    694    273      0]
 [  2639  10737   8988   8906   6201   3473   1475    750    291      0]
 [  1775   7544   7099   7212   5234   3264   1519    683    295      0]
 [  3498  18449  21228  22844  20183  13563   6779   2731   1921      0]
 [  1471   8146  10657  14640  14296  10251   6390   3578   2259      0]]
2022-04-17 03:58:37,036 - INFO - Epoch: 3 | Validation Loss: 92.2049
2022-04-17 04:16:53,956 - INFO - Custom bins confusion matrix:
2022-04-17 04:16:53,957 - INFO - [[1009680  845292  139527   52820   24588   12680    6994    4111    6404
      907]
 [ 368078  562237  154223   71363   35759   19163   10619    6081    9778
     1150]
 [ 151369  328190  124780   66641   36519   20505   11794    7082   11528
     1585]
 [  70046  198058   95056   57284   33295   19451   11748    7188   12205
     1699]
 [  37194  124578   71922   47129   29180   17831   10732    6868   11968
     1874]
 [  22322   81424   54704   38780   25142   15701   10158    6278   11575
     1971]
 [  13777   55316   42565   32360   21671   14083    9041    5848   10909
     1870]
 [   8638   38274   33679   26554   18634   12403    8052    5274   10338
     1895]
 [  20216   94980   99995   87798   66345   46544   31281   21585   44048
     9034]
 [   7515   40881   53556   55759   46996   35757   26358   18492   41584
     9930]]
2022-04-17 04:17:01,656 - INFO - Epoch: 4 | Train Loss: 94.9426
2022-04-17 04:20:38,902 - INFO - Custom bins confusion matrix:
2022-04-17 04:20:38,903 - INFO - [[219290 177163  33127  12227   4949   2134    768    225     59      0]
 [ 76998 119963  36954  17835   7264   2756   1093    293     86      0]
 [ 31137  69324  30010  17631   8110   3261   1326    441    152      0]
 [ 14843  40439  22280  15366   8208   3424   1475    561    191      0]
 [  7530  25009  16541  12979   7425   3704   1481    620    253      0]
 [  4361  17104  12358  10701   6546   3499   1651    666    262      0]
 [  2848  10988   9229   8763   5858   3317   1500    684    273      0]
 [  1861   7792   7171   7177   4960   3242   1458    687    277      0]
 [  3801  18994  21750  22571  19661  13207   6722   2608   1882      0]
 [  1611   8400  10773  14598  14063   9710   6190   3889   2454      0]]
2022-04-17 04:20:41,049 - INFO - Epoch: 4 | Validation Loss: 91.3312
2022-04-17 04:39:09,821 - INFO - Custom bins confusion matrix:
2022-04-17 04:39:09,823 - INFO - [[1005705  850974  139017   52467   24319   12500    6921    3971    6266
      863]
 [ 362471  567605  154426   71653   35920   19081   10563    6131    9437
     1164]
 [ 147057  331086  125620   67634   36106   20386   12020    7047   11547
     1490]
 [  67618  198745   96133   57247   33324   19844   11634    7447   12333
     1705]
 [  35655  124263   72440   47487   29329   18080   11178    6914   12094
     1836]
 [  21447   80875   54605   39065   25617   15954   10193    6581   11865
     1853]
 [  13070   54782   42598   32512   22143   14262    9079    5879   11217
     1898]
 [   8262   37663   33196   26657   18959   12649    8292    5600   10499
     1964]
 [  19438   92846   97843   88401   66739   47304   32267   22218   45308
     9462]
 [   7325   38651   51896   54939   47076   36241   26600   19426   43734
    10940]]
2022-04-17 04:39:17,491 - INFO - Epoch: 5 | Train Loss: 93.9568
2022-04-17 04:42:53,895 - INFO - Custom bins confusion matrix:
2022-04-17 04:42:53,897 - INFO - [[224392 170788  33046  12797   5202   2306    972    349     90      0]
 [ 79040 116312  36683  18164   7959   3232   1230    492    130      0]
 [ 31867  67293  29403  17861   8648   3995   1427    649    249      0]
 [ 15182  39128  21599  15479   8477   4204   1670    716    332      0]
 [  7625  24282  15890  12856   7676   4212   1857    755    389      0]
 [  4501  16446  11772  10522   6895   3764   1997    792    459      0]
 [  2891  10552   8747   8439   6238   3481   1813    874    425      0]
 [  1921   7429   6862   6879   5086   3414   1684    906    441      3]
 [  3840  17941  20806  21186  19472  14018   7700   3706   2523      4]
 [  1637   7930   9928  13328  13998   9784   6937   4396   3750      0]]
2022-04-17 04:42:56,010 - INFO - Epoch: 5 | Validation Loss: 90.4056
2022-04-17 05:01:14,353 - INFO - Custom bins confusion matrix:
2022-04-17 05:01:14,355 - INFO - [[1008063  850052  138273   52385   24295   12284    6749    3861    6214
      827]
 [ 360348  568811  155708   71380   35837   19099   10605    6182    9328
     1153]
 [ 145520  331465  126452   67626   36539   20316   11906    7151   11497
     1521]
 [  66302  198597   96452   57813   33889   19859   11797    7211   12437
     1673]
 [  34642  124431   72094   48027   29429   18317   11142    7022   12295
     1877]
 [  20676   80542   54742   39233   25796   16321   10151    6604   12025
     1965]
 [  12790   54199   42242   32519   22422   14581    9247    5991   11444
     2005]
 [   8091   36687   33123   27057   19231   12685    8382    5611   10798
     2076]
 [  18582   89344   96493   89246   67783   47915   33018   22586   46615
    10244]
 [   6765   37059   49634   53927   46957   36374   27424   19769   46423
    12496]]
2022-04-17 05:01:21,875 - INFO - Epoch: 6 | Train Loss: 92.9681
2022-04-17 05:04:42,999 - INFO - Custom bins confusion matrix:
2022-04-17 05:04:43,000 - INFO - [[222454 174956  31389  12358   5054   2265    986    366    114      0]
 [ 77223 119667  35638  17655   7897   3302   1187    533    140      0]
 [ 30688  69378  28815  17423   8646   4009   1494    680    259      0]
 [ 14662  40291  21215  15243   8334   4186   1768    739    349      0]
 [  7417  24913  15656  12748   7469   4196   2009    726    408      0]
 [  4410  16912  11428  10455   6766   3839   2075    820    443      0]
 [  2862  10804   8564   8394   6188   3428   1873    922    424      1]
 [  1913   7652   6703   6879   4945   3374   1755    949    450      5]
 [  3733  18752  20516  20801  18945  14129   7736   3870   2705      9]
 [  1605   8187   9947  13049  13489   9597   7074   4573   4167      0]]
2022-04-17 05:04:45,152 - INFO - Epoch: 6 | Validation Loss: 89.9025
2022-04-17 05:22:33,154 - INFO - Custom bins confusion matrix:
2022-04-17 05:22:33,155 - INFO - [[1009363  850491  137531   51994   24031   12116    6628    3868    6083
      898]
 [ 357981  571792  156097   71154   35774   18805   10349    5970    9315
     1214]
 [ 144387  331130  127615   67609   36979   20452   11779    7110   11392
     1540]
 [  65767  198219   96752   57963   34103   19902   11816    7109   12553
     1846]
 [  34114  124339   72455   47766   29947   18244   11099    6982   12331
     1999]
 [  20237   80351   54628   39728   26013   16157   10207    6539   12077
     2118]
 [  12387   53742   42336   33202   22383   14400    9461    5968   11423
     2138]
 [   7906   35930   33397   27377   19239   12943    8311    5529   10981
     2128]
 [  18376   87427   95723   88065   68138   48663   33263   22664   48645
    10862]
 [   6825   34474   48733   53120   46819   36824   27425   20274   48480
    13854]]
2022-04-17 05:22:41,085 - INFO - Epoch: 7 | Train Loss: 92.2071
2022-04-17 05:25:59,204 - INFO - Custom bins confusion matrix:
2022-04-17 05:25:59,206 - INFO - [[228513 169328  31285  12304   4985   2153    924    343    107      0]
 [ 79793 117526  35518  17615   7734   3275   1169    488    124      0]
 [ 31957  68163  28883  17467   8724   3865   1454    650    229      0]
 [ 15245  39862  21286  15221   8201   4234   1722    735    281      0]
 [  7726  24687  15817  12606   7518   4212   1951    663    362      0]
 [  4559  16822  11485  10397   6789   3922   2012    731    431      0]
 [  2978  10670   8644   8507   6068   3497   1812    841    443      0]
 [  1964   7534   6843   6967   4876   3313   1780    909    436      3]
 [  3798  18444  20766  21196  19165  13808   7873   3668   2471      7]
 [  1661   8045  10145  13062  13544   9881   7007   4451   3888      4]]
2022-04-17 05:26:01,537 - INFO - Epoch: 7 | Validation Loss: 89.4215
2022-04-17 05:43:42,433 - INFO - Custom bins confusion matrix:
2022-04-17 05:43:42,466 - INFO - [[1010192  851751  136648   51600   23323   12150    6617    3849    6014
      859]
 [ 357474  573767  154775   71106   35851   18744   10390    6015    9147
     1182]
 [ 143727  332083  127350   67605   37024   20500   11682    7149   11295
     1578]
 [  64890  199013   96722   58465   34161   19801   11746    7176   12238
     1818]
 [  33848  123854   72481   47989   30065   18094   11282    7064   12572
     2027]
 [  20039   80118   54606   39656   25950   16474   10277    6550   12256
     2129]
 [  12175   53488   42641   32620   22654   14549    9487    5985   11655
     2186]
 [   7630   36239   32827   27288   19470   12915    8459    5547   11151
     2215]
 [  17853   86931   94553   88130   67874   48118   33652   23304   49826
    11585]
 [   6646   34120   47050   51949   46447   36578   28026   20942   50456
    14614]]
2022-04-17 05:43:50,594 - INFO - Epoch: 8 | Train Loss: 91.6863
2022-04-17 05:47:13,802 - INFO - Custom bins confusion matrix:
2022-04-17 05:47:13,804 - INFO - [[225846 170405  32232  12592   5123   2136   1097    353    158      0]
 [ 77899 117868  36082  17879   8153   3331   1349    506    175      0]
 [ 31038  67978  29028  17557   9082   4109   1603    684    313      0]
 [ 14764  39633  21203  15202   8500   4443   1871    815    356      0]
 [  7445  24437  15811  12481   7695   4397   2086    760    430      0]
 [  4343  16729  11378  10280   6924   4058   2087    827    520      2]
 [  2837  10654   8512   8339   6153   3565   1942    918    536      4]
 [  1890   7382   6865   6827   4941   3292   1931    954    530     13]
 [  3616  17824  20444  21106  19217  13837   8097   4108   2936     11]
 [  1581   7675   9945  12513  13398  10315   7251   4509   4488     13]]
2022-04-17 05:47:15,967 - INFO - Epoch: 8 | Validation Loss: 89.0134
2022-04-17 06:05:14,361 - INFO - Custom bins confusion matrix:
2022-04-17 06:05:14,363 - INFO - [[1011955  851586  136175   50585   23392   12190    6433    3718    6076
      893]
 [ 356856  575142  155121   70901   35183   18532   10174    5998    9419
     1125]
 [ 142570  333431  127708   67592   36440   20375   11697    6988   11586
     1606]
 [  64660  198597   97255   58540   33779   19731   11771    7252   12534
     1911]
 [  33633  123683   72348   48362   29748   18371   11313    7020   12717
     2081]
 [  19879   79784   54736   39375   26161   16276   10427    6675   12571
     2171]
 [  12170   53074   42178   32861   22718   14550    9606    6295   11766
     2222]
 [   7621   35650   32806   27379   19357   13188    8483    5727   11198
     2332]
 [  17629   84711   94139   88179   68696   48879   33712   23319   50728
    11834]
 [   6483   33243   46001   51340   45952   37265   28467   20858   51576
    15643]]
2022-04-17 06:05:22,140 - INFO - Epoch: 9 | Train Loss: 91.1797
2022-04-17 06:08:53,926 - INFO - Custom bins confusion matrix:
2022-04-17 06:08:53,928 - INFO - [[223001 171909  32645  13123   5270   2229   1168    412    185      0]
 [ 76083 118051  36406  18353   8401   3633   1515    572    228      0]
 [ 30091  67881  28708  17829   9508   4366   1841    795    373      0]
 [ 14326  39393  20896  15293   8646   4728   2116    963    426      0]
 [  7235  24218  15481  12347   7825   4732   2263    949    492      0]
 [  4264  16455  11173  10117   6934   4296   2361    934    612      2]
 [  2775  10446   8323   8249   6079   3748   2189    987    659      5]
 [  1869   7143   6716   6677   4992   3365   2108   1101    638     16]
 [  3490  17187  20027  20404  18935  14343   8667   4564   3568     11]
 [  1523   7376   9720  11866  13283  10285   7600   4713   5226     96]]
2022-04-17 06:08:56,022 - INFO - Epoch: 9 | Validation Loss: 88.6809
2022-04-17 06:26:54,666 - INFO - Custom bins confusion matrix:
2022-04-17 06:26:54,668 - INFO - [[1013857  852183  134553   50439   23197   11828    6407    3669    5990
      880]
 [ 356702  576971  154085   70333   35042   18545   10317    5945    9346
     1165]
 [ 142537  334636  127676   66893   36096   20236   11729    6952   11680
     1558]
 [  64699  199064   97349   58057   33835   19666   11833    7204   12352
     1971]
 [  33667  123721   72249   48172   29966   18101   11251    7024   13002
     2123]
 [  19826   79590   54736   40006   25634   16391   10437    6735   12458
     2242]
 [  12029   53066   42089   33143   22501   14682    9451    6212   11947
     2320]
 [   7622   35331   32924   27423   19467   13103    8461    5668   11354
     2388]
 [  17496   83269   93239   87012   68806   49465   34328   23766   51641
    12804]
 [   6399   31262   45206   50895   45414   36948   28488   21301   53636
    17279]]
2022-04-17 06:27:02,475 - INFO - Epoch: 10 | Train Loss: 90.6506
2022-04-17 06:30:21,558 - INFO - Custom bins confusion matrix:
2022-04-17 06:30:21,559 - INFO - [[224823 171098  31679  12821   5388   2215   1229    479    210      0]
 [ 76856 118214  35454  18029   8417   3755   1611    614    292      0]
 [ 30217  68244  28277  17304   9539   4478   2002    900    430      1]
 [ 14384  39764  20480  14872   8732   4664   2232   1098    561      0]
 [  7319  24372  15201  12120   7835   4624   2347   1073    646      5]
 [  4334  16622  10908   9910   6974   4208   2387   1013    778     14]
 [  2806  10572   8172   8043   6011   3768   2168   1110    789     21]
 [  1897   7173   6765   6417   4976   3274   2131   1220    743     29]
 [  3547  17386  19829  19997  18542  13751   9265   4902   3940     37]
 [  1539   7460   9476  11463  12742  10441   7752   4806   5906    103]]
2022-04-17 06:30:23,614 - INFO - Epoch: 10 | Validation Loss: 88.4965
2022-04-17 06:48:24,179 - INFO - Custom bins confusion matrix:
2022-04-17 06:48:24,181 - INFO - [[1016634  850729  133767   49964   23119   11766    6482    3754    5878
      910]
 [ 357266  577149  154068   70214   34886   18233   10284    5738    9296
     1317]
 [ 142080  335963  126832   66500   36264   20342   11805    6993   11488
     1726]
 [  63829  199655   97515   58338   33581   19726   11812    7127   12434
     2013]
 [  33087  123731   72880   48464   29689   18359   11113    7011   12746
     2196]
 [  19362   79922   54585   39701   26115   16351   10279    6856   12488
     2396]
 [  11977   52880   42168   33010   22545   14829    9303    6308   12046
     2374]
 [   7323   35435   32767   27530   19364   13096    8502    5761   11489
     2474]
 [  16992   83051   92210   87732   67945   49080   34558   24094   52505
    13659]
 [   6270   30533   43998   49895   45558   37130   28746   21504   54854
    18340]]
2022-04-17 06:48:31,981 - INFO - Epoch: 11 | Train Loss: 90.2110
2022-04-17 06:51:55,343 - INFO - Custom bins confusion matrix:
2022-04-17 06:51:55,344 - INFO - [[230710 167475  29902  12456   5260   2275   1166    447    251      0]
 [ 79373 117632  34084  17546   8241   3809   1659    570    328      0]
 [ 31442  68442  27281  17002   9339   4475   2083    841    487      0]
 [ 14983  40102  19885  14482   8747   4617   2304   1048    619      0]
 [  7687  24556  14927  11718   7941   4614   2361   1071    660      7]
 [  4537  16859  10691   9649   6920   4310   2363   1011    793     15]
 [  2952  10697   8026   7961   5962   3783   2157   1081    817     24]
 [  1978   7289   6628   6331   4966   3306   2146   1144    804     33]
 [  3704  17723  19474  19942  18146  13887   9262   4882   4129     47]
 [  1649   7568   9583  11150  12573  10514   7423   5077   6055     96]]
2022-04-17 06:51:57,501 - INFO - Epoch: 11 | Validation Loss: 88.1915
2022-04-17 07:09:46,167 - INFO - Custom bins confusion matrix:
2022-04-17 07:09:46,170 - INFO - [[1021726  846772  133594   49381   22888   11657    6529    3641    5862
      953]
 [ 358069  578272  153585   69222   34319   18082   10166    5883    9594
     1259]
 [ 142629  335770  127314   66134   36334   20006   11379    6915   11792
     1720]
 [  64037  200018   97674   58027   33150   19434   11665    7317   12598
     2110]
 [  33059  123903   72786   48021   29964   18231   11151    6949   12916
     2296]
 [  19324   79327   55274   40028   25799   16251   10337    6519   12817
     2379]
 [  11751   52647   42515   32852   22352   14533    9477    6474   12290
     2549]
 [   7205   35228   32639   27215   19358   13210    8587    5951   11763
     2585]
 [  16525   81626   91885   86896   68342   49101   34862   24643   54037
    13909]
 [   5879   28592   43098   49999   45603   36716   28784   21755   56494
    19908]]
2022-04-17 07:09:53,757 - INFO - Epoch: 12 | Train Loss: 89.7206
2022-04-17 07:13:16,100 - INFO - Custom bins confusion matrix:
2022-04-17 07:13:16,102 - INFO - [[228554 169626  29525  12280   5446   2416   1236    518    341      0]
 [ 78198 118891  33673  17275   8335   3900   1846    698    425      1]
 [ 30780  69166  27004  16661   9095   4845   2290    939    597     15]
 [ 14564  40520  19714  14299   8364   4905   2449   1169    801      2]
 [  7418  24707  14906  11358   7841   4707   2546   1179    859     21]
 [  4446  16946  10639   9311   6760   4409   2490   1174    937     36]
 [  2905  10722   7998   7679   5791   3822   2306   1175   1032     30]
 [  1941   7314   6587   6085   4880   3283   2218   1238   1045     34]
 [  3582  17701  19418  19104  17645  13770   9529   5187   5168     92]
 [  1652   7485   9340  10674  12167  10469   7607   5290   6821    183]]
2022-04-17 07:13:18,342 - INFO - Epoch: 12 | Validation Loss: 88.1547
2022-04-17 07:31:13,002 - INFO - Custom bins confusion matrix:
2022-04-17 07:31:13,006 - INFO - [[1021652  849403  131937   49023   22615   11558    6350    3597    6011
      857]
 [ 357587  580160  153443   68080   34255   18151   10190    6030    9279
     1276]
 [ 142315  337168  127084   65820   35747   19879   11547    7004   11728
     1701]
 [  63827  201125   97121   57286   33378   19557   11691    7292   12708
     2045]
 [  32818  124452   72949   47734   29591   18288   11127    7092   13002
     2223]
 [  19141   79702   55336   39331   25650   16432   10309    6821   12921
     2412]
 [  11534   52993   41910   33102   22506   14712    9587    6274   12307
     2515]
 [   7086   35445   32315   27419   19350   13009    8706    5962   11793
     2656]
 [  16588   81303   90846   86369   68422   49493   35010   24625   54432
    14738]
 [   5743   28622   41749   48539   44981   37079   29002   21998   57830
    21285]]
2022-04-17 07:31:20,902 - INFO - Epoch: 13 | Train Loss: 89.3988
2022-04-17 07:34:43,874 - INFO - Custom bins confusion matrix:
2022-04-17 07:34:43,876 - INFO - [[225409 172501  30416  12183   5181   2269   1167    519    297      0]
 [ 76529 120183  34618  16991   8402   3691   1739    725    354     10]
 [ 29924  70040  27472  16478   9032   4743   2123    951    610     19]
 [ 14196  40767  20284  14072   8411   4718   2341   1218    774      6]
 [  7232  24928  15217  11205   7823   4563   2450   1273    823     28]
 [  4249  17117  10993   9141   6827   4224   2424   1221    912     40]
 [  2745  10917   8196   7527   5902   3734   2274   1125   1011     29]
 [  1888   7346   6789   5965   5044   3151   2203   1134   1071     34]
 [  3465  17707  20079  19294  17727  12948   9691   5109   5120     56]
 [  1598   7510   9790  11012  12071  10433   6940   5089   7108    137]]
2022-04-17 07:34:46,191 - INFO - Epoch: 13 | Validation Loss: 88.1057
2022-04-17 07:52:27,190 - INFO - Custom bins confusion matrix:
2022-04-17 07:52:27,192 - INFO - [[1024314  847992  131252   48602   22320   11409    6481    3749    5915
      969]
 [ 358110  580172  153424   68041   33838   18106   10100    5891    9412
     1357]
 [ 141595  338200  127289   65862   35167   19547   11516    6996   11972
     1849]
 [  63914  201145   97734   56889   33019   19489   11735    7222   12728
     2155]
 [  32986  123760   73545   48149   29415   17723   11121    7110   13073
     2394]
 [  18869   79648   55751   39311   25568   16412   10304    6793   12904
     2495]
 [  11467   52716   42353   32995   22427   14547    9453    6400   12443
     2639]
 [   7048   34970   32799   27307   19498   12899    8667    5900   11923
     2730]
 [  16368   79937   91335   86588   67865   49120   35088   24824   55496
    15205]
 [   5751   27774   41290   47339   44188   37177   28804   22684   59375
    22446]]
2022-04-17 07:52:35,105 - INFO - Epoch: 14 | Train Loss: 89.0803
2022-04-17 07:55:58,145 - INFO - Custom bins confusion matrix:
2022-04-17 07:55:58,146 - INFO - [[229073 169301  29238  11941   5585   2539   1258    655    347      5]
 [ 78427 118866  33230  16738   8651   4076   1933    888    419     14]
 [ 30899  69300  26503  16363   9130   5023   2288   1143    713     30]
 [ 14616  40539  19527  13815   8456   4981   2476   1380    985     12]
 [  7465  24772  14519  11068   7831   4901   2502   1403   1048     33]
 [  4455  16923  10561   8818   6890   4384   2663   1275   1132     47]
 [  2888  10782   7856   7351   5850   3789   2461   1228   1214     41]
 [  1947   7317   6501   5795   4872   3370   2254   1248   1275     46]
 [  3600  17667  19109  18520  16658  13544  10201   5704   6068    125]
 [  1718   7483   9262  10458  11314  10524   7504   5294   8060     71]]
2022-04-17 07:56:00,333 - INFO - Epoch: 14 | Validation Loss: 87.9036
2022-04-17 07:56:00,346 - INFO - Experiment ended. Checkpoints stored =)
